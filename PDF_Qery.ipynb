{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.llms.ollama import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType, Tool, initialize_agent\n",
    "from langchain.agents import load_tools\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with open(pdf_path, \"rb\") as f:\n",
    "        pdf_reader = PyPDF2.PdfReader(f)\n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            text += page.extract_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q4/8hxfb0hn2fb4qx0gwrhjbrwc0000gn/T/ipykernel_24302/4133009502.py:7: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"llama3\")  # Make sure Ollama supports this model\n",
      "/var/folders/q4/8hxfb0hn2fb4qx0gwrhjbrwc0000gn/T/ipykernel_24302/4133009502.py:10: LangChainDeprecationWarning: This class is deprecated. See the following migration guides for replacements based on `chain_type`:\n",
      "stuff: https://python.langchain.com/docs/versions/migrating_chains/stuff_docs_chain\n",
      "map_reduce: https://python.langchain.com/docs/versions/migrating_chains/map_reduce_chain\n",
      "refine: https://python.langchain.com/docs/versions/migrating_chains/refine_chain\n",
      "map_rerank: https://python.langchain.com/docs/versions/migrating_chains/map_rerank_docs_chain\n",
      "\n",
      "See also guides on retrieval and question-answering here: https://python.langchain.com/docs/how_to/#qa-with-rag\n",
      "  qa_chain = load_qa_chain(llm, chain_type=\"stuff\")  # \"stuff\" is the basic chain type\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import Ollama\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "# Initialize Ollama LLM\n",
    "llm = Ollama(model=\"llama3\")  # Make sure Ollama supports this model\n",
    "\n",
    "# Load the question-answering chain\n",
    "qa_chain = load_qa_chain(llm, chain_type=\"stuff\")  # \"stuff\" is the basic chain type\n",
    "\n",
    "# Function to query the PDF text\n",
    "def query_pdf(pdf_text, query):\n",
    "    doc = Document(page_content=pdf_text)\n",
    "    response = qa_chain.run(input_documents=[doc], question=query)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q4/8hxfb0hn2fb4qx0gwrhjbrwc0000gn/T/ipykernel_24302/1373651669.py:6: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = qa_chain.run(input_documents=[doc], question=query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the given context, I can see that there are two categories: Retail and Restaurant. Under the Retail category, we have:\n",
      "\n",
      "* Walmart: 100\n",
      "* Shoppers: 500\n",
      "\n",
      "Total Retail expenses would be the sum of these amounts:\n",
      "100 + 500 = 600\n",
      "\n",
      "Therefore, the answer is 600.\n"
     ]
    }
   ],
   "source": [
    "def query_pdf(pdf_text, query):\n",
    "    # Create a Document object from the extracted text\n",
    "    doc = Document(page_content=pdf_text)\n",
    "    \n",
    "    # Run the question-answering chain\n",
    "    response = qa_chain.run(input_documents=[doc], question=query)\n",
    "    return response\n",
    "\n",
    "# Example usage\n",
    "pdf_path = \"sample_pdf_expense.pdf\"\n",
    "pdf_text = extract_text_from_pdf(pdf_path)\n",
    "query = \"Total retail expences\"\n",
    "\n",
    "response = query_pdf(pdf_text, query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
